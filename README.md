# Исследование эффективности модификаций сети Faster R-CNN для задачи обнаружения дефектов на поверхности металлопроката

Авторы:
1. Залялутдинова Карина, 312496
2. Корнюшенков Роман, 339600
3. Алексанр Медведев, 286511

## Цель работы
Исследовать и сравнить архитектурные модификации базовой сети Faster R-CNN и выявить наиболее эффективные улучшения для задачи обнаружения поверхностных дефектов металлопроката.

## Описание используемого датасета
В рамках курсового проекта использовался датасет NEU-DET (Northeastern University Surface Defect Dataset).

NEU-DET - это общедоступный датасет для обнаружения дефектов на поверхности стальных листов.

Датасет содержит 1800 фотографий и 6 типов дефектов: 
- сrazing (трещины на поверхности),
- inclusion (включения инородных материалов), 
- patches (пятна и участки с изменённой текстурой),
- pitted surface (точечная коррозия поверхности), 
- rolled-in scale (окалина, вкатанная в поверхность),
- scratches (царапины).

![Датасет NEU-DET](images/0h7IhGFBcm2AWu1eAAKVXvx7IaI250.jpg)

## Описание исследования 
В рамках курсового проекта были исследованы 3 модификации модели Faster R-CNN:
1. Модификация, включающая деформированные сверточные слои и гибридный модуль внимания;
2. Модификация, включающая оптимизированный модуль слияния признаков и легкий механизм канального внимания (также дополнительно было исследовано добавление к представленной архитектуре деформированные сверточные слои);
3. Модификация, включающая Feature Pyramid Network и деформированный сверточный слой.

## Модификация 1
Источник: [Cui G., Zhang L. Improved faster region convolutional neural network algorithm for UAV target detection in complex environment //Results in Engineering. – 2024. – Т. 23. – С. 102487.](https://www.sciencedirect.com/science/article/pii/S2590123024007424)

Данная реализация представляет собой модификацию алгоритма Faster R-CNN, оптимизированную для обнаружения целей на изображениях с беспилотных летательных аппаратов (БПЛА) в сложных условиях.

Модифицированная модель включает в себя:
- Гибридный модуль внимания: CAM (Channel Attention Module) и SAM (Spatial Attention Module)
- Слои с деформированными свертками

#### Деформируемые сверточные слои (Deformable Convolution)
Стандартные сверточные нейронные сети (CNN) используют фиксированную геометрическую структуру для выборки признаков (регулярная сетка). Это ограничивает их способность моделировать геометрические трансформации, такие как изменение масштаба, позы или деформация объектов.

![Деформируемый сверточный слой](images/deformable-conv-7d1bf75bdd8c187a81515430d7ba2964.png)

Для стандартной свертки выходное значение в позиции $p_0$ вычисляется как:
$$y(p_0) = \sum_{p_n \in R} w(p_n) \cdot x(p_0 + p_n),$$
где $R$ — регулярная сетка выборки, 
$w$ — веса ядра, $x$ — входная карта признаков.

В деформируемой свертке к позициям выборки добавляются обучаемые смещения $Δp_n$:
$$y(p_0) = \sum_{p_n \in R} w(p_n) \cdot x(p_0 + p_n + \Delta p_n)$$

Модификации применяются к слоям `layer2`, `layer3` и `layer4`, используя класс `DeformConv2d`.

#### Гибридный модуль внимания (Hybrid Attention Module)
Изображения с БПЛА часто имеют сложный фон, плотное распределение целей и малое количество пикселей, занимаемых объектом, что справедливо и для изображений поверхностных дефектов металлопроката. Чтобы снизить влияние нерелевантной информации и повысить чувствительность к целям, используется гибридный механизм внимания, сочетающий канальное и пространственное внимание.

Канальное внимание (Channel Attention Module, CAM) сжимает пространственную информацию карты признаков, используя глобальное усреднение и глобальный максимум, чтобы выявить значимые каналы.

Пространственное внимание (Spatial Attention Module, SAM) сжимает информацию по каналам (используя среднее и максимум вдоль размерности каналов), чтобы выделить важные пространственные области

Гибридный модуль внимания последовательно применяет CAM и SAM для уточнения карт признаков.

Ссылка на Colab с реализованной модификацией: [https://colab.research.google.com/drive/1dzb5tlvOx2Rn7kPUgjpHZH0Tcf4iCnlV?usp=sharing](https://colab.research.google.com/drive/1UGn-vORpz6G5fag3izhvazVXNZposWdX#scrollTo=zgTb1EnIQ_mb)

## Модификация 2
Ссылка на статью: [Leng Y., Liu J. Improved faster R-CNN for steel surface defect detection in industrial quality control //Scientific Reports. – 2025. – Т. 15. – №. 1. – С. 30093.](https://www.nature.com/articles/s41598-025-12740-x)

Авторами предложено два ключевых изменения в базовую архитектуру Faster R-CNN для улучшения способности модели к извлечению тонких признаков и фокусировки на областях дефектов.

### Оптимизированный модуль слияния признаков (Feature Fusion Module - FFM)

Для улучшения интеграции семантических признаков высокого уровня и пространственных признаков низкого уровня в сеть пирамиды признаков (FPN) был внедрен специализированный модуль слияния. Модуль располагается между уровнями P3 и P2.
Входными данными модуля являются карты признаков высокого и низкого уровней, описываемые формулами:

$$
F_{high} \in \mathbb{R}^{C_{high} \times H_{high} \times W_{high}} \qquad (1)
$$

$$
F_{low} \in \mathbb{R}^{C_{low} \times H_{low} \times W_{low}} \qquad (2)
$$

где C, H и W обозначают количество каналов, высоту и ширину карты признаков соответственно.

Процесс формирования новой объединенной карты признаков Fnew описывается следующим выражением:

$$
F_{new} = \text{ReLU}[\text{BatchNorm}(F'_{high} + F'_{low})] \qquad (3)
$$

Пояснение к формулам:
- Fhigh и Flow — промежуточные представления карт признаков уровней P3 и P2 после операций повышения размерности (upsampling) и свертки.
- Для обеспечения пространственного согласования высокоуровневые признаки увеличиваются с помощью билинейной интерполяции до размеров низкоуровневых признаков.
- Сверточный слой с ядром 3×3 используется для стандартизации количества каналов обоих уровней до 256.
- Операция поэлементного суммирования (+) объединяет семантику и пространственную детализацию.
- BatchNorm(пакетная нормализация) стабилизирует распределение активаций, а ReLU (функция активации) вводит нелинейность и отсеивает шумовые значения.

### Легкий механизм канального внимания (Lightweight Channel Attention Mechanism — LCAM)

Модуль легкого канального внимания (LCAM) интегрирован в архитектуру улучшенного Faster R-CNN между выходом сети пирамиды признаков (FPN) и входом сети предложений регионов (RPN). Основная задача модуля — усилить фокус модели на значимых областях дефектов поверхности стали и подавить отклик на нерелевантные признаки фона. Это позволяет повысить дискриминационную способность модели, улучшая точность распознавания особенно мелких и сложных дефектов.

Структура модуля: Архитектура LCAM состоит из следующих последовательных слоев:
1.	Сверточный слой понижения размерности: Свертка с ядром 3×3, уменьшающая количество каналов входной карты признаков с 256 до 128.
2.	Слой активации ReLU: Вводит нелинейность, обнуляя отрицательные значения.
3.	Сверточный слой восстановления размерности: Свертка с ядром 3×3, возвращающая количество каналов с 128 обратно до 256.
4.	Слой активации Sigmoid: Генерирует веса внимания в диапазоне [0,1] для каждого канала.
5.	Операция слияния: Поэлементное умножение исходной карты признаков FPN на полученную карту весов внимания.

$$
\text{ReLU}(x) = \max(0, x) \qquad (4)
$$

$$
\sigma(x) = \frac{1}{1 + e^{-x}} \qquad (5)
$$

$$
W_1 \in \mathbb{R}^{C_{reduced} \times C \times 3 \times 3}, \quad W_2 \in \mathbb{R}^{C \times C_{reduced} \times 3 \times 3} \qquad (6)
$$

$$
b_1 \in \mathbb{R}^{1 \times C_{reduced}}, \quad b_2 \in \mathbb{R}^{2 \times C_{reduced}} \qquad (7)
$$

$$
F(X) = X \odot \sigma(W_2 * \max(0, W_Z * X + b_1) + b_2) \qquad (8)
$$

Пояснение к формулам:
- ReLU(x) и σ(x) (Формулы 4 и 5): Описывают нелинейные преобразования. ReLU сохраняет положительные активации после первого сверточного слоя, способствуя разреженности представлений. Сигмоидная функция σ(x) на выходе второго слоя сжимает значения в диапазон [0,1] интерпретируемые как веса важности каналов (1 — высокая важность, 0 — шум/фон).
- W1,W2 и b1,b2 (Формулы 6 и 7): Определяют обучаемые параметры двух сверточных операций.
- X — входная карта признаков (C=256).
- W1— веса первого слоя (понижение размерности до Creduced=128).
- W2— веса второго слоя (восстановление размерности до C=256).
- Ядро свертки имеет размер 3×3для сохранения пространственной структуры.
- F(X) (Формула 8): Описывает полный проход данных через модуль внимания.
- Wz∗X+b1: Первая свертка (в тексте статьи обозначена как Wz, что соответствует W1из Формулы 6).
- max(0,…): Применение ReLU.
- W2∗(...)+b2: Вторая свертка.
- σ(...)Применение сигмоиды для получения карты весов.
- X⊙...: Поэлементное умножение исходной карты признаков X на карту весов внимания.
- F(X): Итоговая уточненная карта признаков, передаваемая на вход RPN.

Ссылка на Colab с реализованной модификацией: https://colab.research.google.com/drive/1dzb5tlvOx2Rn7kPUgjpHZH0Tcf4iCnlV?usp=sharing

## Модификация 3
Данная модификация представляет собой модификацию 2 с деформируемыми свертаками из модификации 1, таким образом она содержит:
- Деформируемые свертки
- Feature Fusion Module
- Lightweight Channel Attention Mechanism

Ссылка на Colab с реализованной модификацией: https://colab.research.google.com/drive/1a7HZRN8OOq29_WGWroqxslUpf-yRpwk6?usp=sharing

## Модификация 4

**Faster RCNN VGG16 + DCNv1 + FPN**

**Источник:** Object Detector for Autonomous Vehicles Based on Improved Faster-RCNN URL: https://github.com/Ziruiwang409/improved-faster-rcnn

**Основа:** Faster RCNN, бэкбон: VGG16

**Улучшения:**

1. Деформируемые сверточные сети (DCNv1). Статья: Jifeng Dai, Haozhi Qi, Yuwen Xiong, Yi Li. Deformable Convolutional Networks URL: https://arxiv.org/abs/1703.06211
2. Сеть пирамидальных признаков (FPN). Статья: Tsung-Yi Lin, Piotr Dollár, Ross Girshick. Feature Pyramid Networks for Object Detection. URL: https://arxiv.org/abs/1612.03144

Ссылка на Colab с реализованной модификацией: https://colab.research.google.com/drive/1a7wbUbS7Ylz5H3t6sR4_7lqh2K44bX_Y?usp=sharing

## Сравнительный анализ результатов
В данном разделе представлены результаты тестирования различных модификаций модели Faster R-CNN на датасете NEU-DET. Сравнение проводится между базовыми архитектурами (Backbone ResNet50 и VGG16) и предложенными улучшенными конфигурациями.

Общие метрики производительности

| Метрика | base ResNet50 | base VGG16 | Модификация 1 | Модификация 2 | Модификация 3 | Модификация 4 |
| :--- | :---: | :---: | :---: | :---: | :---: | :---: |
| **mAP@0.5** | 0.7690 | 0.6078 | 0.7401 | 0.7802 | **0.7832** | 0.7467 |
| **Precision** | 0.6170 | 0.3700 | 0.5786 | **0.6296** | 0.6198 | 0.5100 |
| **Recall** | 0.7600 | 0.7300 | 0.7289 | 0.7611 | **0.7626** | 0.7600 |
| **F1** | 0.6811 | 0.4900 | 0.6451 | **0.6891** | 0.6838 | 0.6100 |

Наилучшие общие результаты по основной метрике mAP@0.5 демонстрирует Модификация 3 (0.7832), что превышает показатели базовой модели ResNet50 на 1.4%. Также Модификация 3 лидирует по метрике Recall (0.7626), что указывает на её способность находить наибольшее количество целевых объектов.
Модификация 2 показывает лучшие результаты по метрикам Precision (0.6296) и F1-мера (0.6891). Это говорит о том, что данная модель допускает наименьшее количество ложных срабатываний и имеет наилучший сбалансированный показатель.

Метрики по классам дефектов 
| Класс дефекта | base ResNet50 | base VGG16 | Модификация 1 | Модификация 2 | Модификация 3 | Модификация 4 |
| :--- | :---: | :---: | :---: | :---: | :---: | :---: |
| **crazing** | 0.3166 | 0.4000 | 0.3238 | 0.3575 | 0.3863 | **0.4600** |
| **inclusion** | 0.8587 | 0.4800 | 0.8219 | 0.8726 | **0.8826** | 0.7100 |
| **patches** | **0.9529** | 0.8700 | 0.8908 | 0.9313 | 0.9504 | 0.9500 |
| **pitted surface** | 0.8824 | 0.8900 | 0.8305 | 0.8972 | 0.8832 | **0.9300** |
| **rolled-in scale** | 0.6197 | 0.6300 | 0.5859 | 0.6404 | 0.6154 | **0.7300** |
| **scratches** | 0.9840 | 0.3700 | **0.9880** | 0.9823 | 0.9814 | 0.7000 |

 
Производительность по классам:
- Модификация 4 демонстрирует высокие результаты в классах, которые сложно детектировать: crazing (0.4800), pitted surface (0.9000) и rolled-in scale (0.7600). Это свидетельствует о высокой эффективности данной конфигурации для специфических текстурных дефектов.
- Для класса inclusion лучший результат показывает Модификация 3 (0.8826).
Поверхностные дефекты: Для класса scratches (царапины) все модификации показывают высокую точность, но лидером остается Модификация 1 (0.9880).

Внедрение предложенных модулей позволяет преодолеть ограничения базовых моделей. Модификация 3 рекомендуется для задач, где критично не пропустить дефект (максимальный mAP и Recall), а Модификация 2 — для задач, где важно минимизировать ложные срабатывания (максимальная Precision и F1). Модификация 4 показывает наилучшие результаты для специфических классов дефектов (crazing, rolled-in scale).

## Запуск кода
Реализованные модификации могут быть запущены по ссылкам в Google Colab.

Локально загрузить описанные модификации можно с помощью команды:

```
git clone https://github.com/kzalyalutdinova/MachineLearning_CourseProject.git
```

Чекпоинты модификаций с лучшими весами находятся в папке checkpoints

